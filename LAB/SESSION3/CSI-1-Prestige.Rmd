---
title: "CSI-1-Prestige"
author: "Walter J.T.V"
date: "`r Sys.Date()`"
output: html_document
---

# Exercise

## Libraries

```{r}
library(AER)
library(FactoMineR)
library(car)
library(mice)
library(missMDA)
library(EnvStats) # For variance tests
```

Response to study:  prestige of occupation. 

Firstly, create a new factor, dichotomy, indicating if an occupation refers to professional and managerial duties or not. Afterwards, answer the following questions, using graphical and inferential tools.

1. Does prestige seem to be normally distributed? 
2. Calculate a 95% CI for prestige mean.
3. Calculate a 95% CI for prestige variance.
5. Does the dispersion of prestige depend on the type of occupation? Or on having professional/managerial  profile?  Formulate and quantify pvalues for testing group variances.
6. How would you test whether the prestige between blue and white collar occupations significantly differ or not?
7. Use condes() in FactoMineR package to check your previous conclusions.

## 1. Prestige distribution

Computing its mean and standard deviation we will compare the histogram to the result of the normal function using as parameters the computed mean and std. 
```{r}

df <- Prestige
df$f.prof <- 0 
df$f.prof[df$type == "prof"] <- 1 
df$f.prof <- factor(df$f.prof, labels=c("professor, not_professor"))


prestige_mean = mean(df$prestige)
prestige_sd = sd(df$prestige)

#The curve command is linked to the histogram therefore "x" is the same data
#hist(df$prestige, breaks = 12, freq = FALSE, col = "red", main = "Histogram of Prestige vs Normal Curve", xlab = "Prestige", ylab = "Density")
#curve(dnorm(x, mean = prestige_mean, sd = prestige_sd), col = "blue", lwd = 2, add = TRUE)
qqnorm(df$prestige, main="Q-Q Plot for Prestige", xlab= "Theoretical quantiles :)", ylab="Sample quantiles")
qqline(df$prestige, col="red", lwd=2)

#Perform a SHAPIRO normality test. H0: prestige is normally distributed  
shapiro.test(df$prestige)

#Perform a Kolmogorov Smirnov general purpose test  (To test between 2 probability distributions)
ks.test(df$prestige, "pnorm", mean=prestige_mean, sd=prestige_sd)
```
## 2. Mean confidence interval (95%)

Now we are going to check if the mean is equal to 50 with a 95% confidence interval. We also want to see with a 99% confidence interval if the mean is less than 50. Given that we don't know the true population parameters we will use t-test. 

Conclusion: We fail to reject the Null
```{r}

#Two-sided (Ho: mu = 50)
t.test(df$prestige, conf.level=0.95, mu=50, alternative= "two.sided")

#One sided (Ho: mu < 50)
t.test(df$prestige, conf.level=0.99, mu=50, alternative="less")

#Non-parametric test example W (Great for not normally distributed data)
wilcox.test(df$prestige, mu=50, conf.int=T)
```

## 3. Variance confidence interval (95%)

Following up a testing on the variance will be made

Conclusion:

```{r}

``` 


## 4. Prestige and occupation Relationship


```{r}

#If its normally distributed then we can test it by hypothesis (ANOVA)
# H0: means of groups defined by its type are equal 

#?oneway.test
oneway.test(df$pre ~ df$type)

kruskal.test(df$prestige ~ df$type)

#Binary factor f.prof test 

wilcox.test(df$prestige ~ df$f.prof)
t.test(df$prestige ~ df$f.prof)

# H0: Mean_bluecollar = Mean_whitecollar -> rejection  of H0
# Parametric test 
pairwise.t.test(df$prestige, df$type)

# H0: Mean_bluecollar = Mean_whitecollar -> rejection  of H0
# Non-parametric test: No assumption about normality of the distribution of data is made
pairwise.wilcox.test(df$prestige, df$type)

```


## 5. Dispersion of prestige

Does the dispersion of prestige depend on the type of occupation? Or on having professional/managerial  profile?  Formulate and quantify pvalues for testing group variances

```{r}
#R FORMULA
#LEFT SIDE: DATA VALUES 
#RIGHT SIDE: groups

#If normally distributed target -- parametric test on variances
# H0: Sigma1² = Sigma2² = Sigma3² = Sigma² ----> Fail to reject H0
bartlett.test(df$prestige ~ df$type)

#Binary testing on f.prof 
# H0: Sprofessor = Snon_professor
var.test(df$prestige ~ df$f.prof)

#Non-parametric test on variances: No normal distribution for prestige is assumed 
# H0: same as past ones --> FAIL TO REJECT H0 IN BOTH CASES
fligner.test(df$prestige ~ df$type)

fligner.test(df$prestige ~ df$f.prof)


```


As a summary of kinds of tests, we can asses in a table if they are parametric or not and

### Tests Matrix: Parametric/Non-Parametric and Target Sample Variable

| Target Variable    | Parametric Tests               | Non-Parametric Tests        | Number of Levels  |
|--------------------|--------------------------------|-----------------------------|-------------------|
| **Mean**           | `t.test()`                     | `wilcox.test()`  | 2 groups          |
|                    | `oneway.test()` (ANOVA)        | `kruskal.test()` | More than 2 groups|
| **Variance**       | `var.test()`                   | N/A                         | 2 groups          |
|                    | `bartlett.test()`              | `fligner.test()`             | More than 2 groups|


## 7. Asses previous conclusions

Use condes() in **FactoMineR** package to check your previous conclusions.

```{r}
df$census <- NULL

#Target is prestige variable
res_con <- condes(df, num.var=4)

attributes(res_con)

#Association between prestige and the rest of numeric vars in the DF 
res_con$quanti

#Global assocation between prstige and qualitative variables
res_con$quali 

#Details of association between prestige and the levels of factors in df
res_con$category





```

Conclusions:


## Artificial last example 

The target variable is type 

```{r}

names(df)
#profiling for factors with catdes() 

res_cat <- catdes(df, 5)
attributes(res_cat)

#TEST CHI2: factors in df that are globally related to target type
res_cat$test.chi2

#Levels in factors in df that are related to target levels (type)
res_cat$category
```

